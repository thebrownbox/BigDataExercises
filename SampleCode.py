%spark.pyspark
temp1 = (data_df.where(data_df.organization == '24h')
                    .groupBy("category")
                    .agg(F.count("headline").alias("Total"))
                    .orderBy("Total", ascending=False))
z.show(temp1)
temp2 = (data_df.where(data_df.organization == 'ThanhNien')
                    .groupBy("category")
                    .agg(F.count("headline").alias("Total"))
                    .orderBy("Total", ascending=False))
z.show(temp2)
temp3 = (data_df.where(data_df.organization == 'Afamily')
                    .groupBy("category")
                    .agg(F.count("headline").alias("Total"))
                    .orderBy("Total", ascending=False))
z.show(temp3)